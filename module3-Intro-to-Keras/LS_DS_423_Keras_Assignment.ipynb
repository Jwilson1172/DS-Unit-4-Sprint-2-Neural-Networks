{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz', test_split=0.2, seed=113\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, AlphaDropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_33 (Dense)             (None, 128)               1792      \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_34 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_35 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 10,113\nTrainable params: 10,113\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "\n",
    "# earlystopping settings\n",
    "stop = EarlyStopping(monitor='val_mape', min_delta=0.05, patience=3)\n",
    "\n",
    "def build_model():\n",
    "  model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=[len(x_train[0])]),\n",
    "    Dropout(rate=0.05),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.005)\n",
    "\n",
    "  model.compile(loss='mae',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse','mape'])\n",
    "  return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n13/13 [==============================] - 0s 14ms/step - loss: 57.9690 - mae: 57.9690 - mse: 9100.7217 - mape: 310.9539 - val_loss: 11.7122 - val_mae: 11.7122 - val_mse: 197.6883 - val_mape: 48.0124\nEpoch 2/100\n13/13 [==============================] - 0s 5ms/step - loss: 16.9210 - mae: 16.9210 - mse: 401.1700 - mape: 92.3471 - val_loss: 13.8985 - val_mae: 13.8985 - val_mse: 244.6902 - val_mape: 86.4365\nEpoch 3/100\n13/13 [==============================] - 0s 5ms/step - loss: 10.5681 - mae: 10.5681 - mse: 175.0760 - mape: 53.2272 - val_loss: 10.7442 - val_mae: 10.7442 - val_mse: 153.7044 - val_mape: 69.0621\nEpoch 4/100\n13/13 [==============================] - 0s 5ms/step - loss: 8.7756 - mae: 8.7756 - mse: 123.9581 - mape: 45.1261 - val_loss: 9.4326 - val_mae: 9.4326 - val_mse: 117.6140 - val_mape: 58.8289\n"
    }
   ],
   "source": [
    "# tensorboard config settings\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "hist = model.fit(x_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm the data by 255 to acount the bitdepth\n",
    "X_test = X_test / 255\n",
    "X_train = X_train / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, AlphaDropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3969 - accuracy: 0.8824 - val_loss: 0.1893 - val_accuracy: 0.9436\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1958 - accuracy: 0.9412 - val_loss: 0.1551 - val_accuracy: 0.9531\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1565 - accuracy: 0.9533 - val_loss: 0.1292 - val_accuracy: 0.9635\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1378 - accuracy: 0.9581 - val_loss: 0.1222 - val_accuracy: 0.9636\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1240 - accuracy: 0.9621 - val_loss: 0.1180 - val_accuracy: 0.9656\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fd5194663d0>"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "# add tensorboard callback\n",
    "MODEL_NAME = \"mnist_classexmpl0\"\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+MODEL_NAME)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# add early stopping\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
    "\n",
    "# make a model arch with some layers\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(rate=0.05),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model arch with the tnsorboard and stop callbacks\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=5,\n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, AlphaDropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tensorboard callback\n",
    "MODEL_NAME = \"cnn_mnist\"\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+MODEL_NAME)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# add early stopping\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
    "\n",
    "\n",
    "# compile model \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model arch with the tnsorboard and stop callbacks\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=5,\n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def build_model(self,layers:list=None) -> tf.keras.Model:\n",
    "        if layers != None:\n",
    "            model = Sequential(layers=layers)\n",
    "        else:\n",
    "            model = Sequential([\n",
    "\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(rate=0.05),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(10,activation=\"softmax\")\n",
    "\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('intro_nn': conda)",
   "language": "python",
   "name": "python37664bitintronncondabe27099557db4cd1a4d5547b016f4f28"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}