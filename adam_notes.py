adam_params = {'alpha': 0.001,
               'beta1': 0.9,
               'beta2': 0.999,
               'epsilon': 10e-8}
# explination:
# alpha - Also referred to as the learning rate or step size.
# The proportion that weights are updated (e.g. 0.001).
# Larger values (e.g. 0.3) results in faster initial learning before the rate is updated.
# Smaller values
# (e.g. 1.0E-5) slow learning right down during training
